{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DATA_COAE.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ncMnki7SSQNs","colab_type":"code","colab":{}},"cell_type":"code","source":["COAE：中文数据集\n","\n","中文数据处理：\n","1、数据（去停用词）、分词、标词性、句法分析，\n","2、对未登录词进行均匀分布随机化\n","3、train与test同时统计\n","\n","#词向量、词性向量、位置向量、句法结构\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E501e7FjAPuV","colab_type":"code","colab":{}},"cell_type":"code","source":["#中文数据集 COAE\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data.dataloader as dataloader\n","import torch.optim as optim\n","import torch.autograd as autograd\n","#import torchtext.vocab as torchvocab\n","from torch.autograd import Variable\n","import tqdm\n","import os\n","import time\n","import re\n","import pandas as pd\n","import string\n","import gensim\n","#from gensim.models import word2vec\n","import time\n","import random\n","import nltk\n","import snowballstemmer\n","import collections\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from itertools import chain\n","from sklearn.metrics import accuracy_score\n","import pyltp\n","from pyltp import Segmentor\n","from pyltp import Postagger\n","from pyltp import Parser\n","num_epochs = 200  #训练迭代次数\n","embed_size = 300  #词向量维度\n","num_hiddens = 128 #隐藏层神经单元个数\n","num_layers = 2    #隐藏层层数\n","bidirectional = True  #False为LSTM,True为双向LSTM\n","#batch_size = 64    #批处理大小\n","labels = 2          #二分类"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E4FYFzQVXfEt","colab_type":"code","outputId":"92dcee71-911a-4c71-beb0-ccf8ede431cf","executionInfo":{"status":"ok","timestamp":1556805515236,"user_tz":-480,"elapsed":450299,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":196}},"cell_type":"code","source":["!pip install pyltp"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting pyltp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/72/2d88c54618cf4d8916832950374a6f265e12289fa9870aeb340800a28a62/pyltp-0.2.1.tar.gz (5.3MB)\n","\u001b[K     |████████████████████████████████| 5.3MB 45.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyltp\n","  Building wheel for pyltp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/fc/3a/35/b11293efb2c77c0e7b6fa574271d51cddd9abd1f634535343c\n","Successfully built pyltp\n","Installing collected packages: pyltp\n","Successfully installed pyltp-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"RtkAC7G0DCZy","colab_type":"code","outputId":"9d031537-22af-48cf-a824-24497e4b3f96","executionInfo":{"status":"ok","timestamp":1547273308047,"user_tz":-480,"elapsed":51810,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":138}},"cell_type":"code","source":[" !pip install torch==0.4"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch==0.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n","\u001b[K    100% |████████████████████████████████| 484.0MB 29kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x5c508000 @  0x7f5a2271e2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n","\u001b[?25hInstalling collected packages: torch\n","Successfully installed torch-0.4.0\n"],"name":"stdout"}]},{"metadata":{"id":"ENT27h61DCkg","colab_type":"code","outputId":"b63005a4-9301-457a-b773-06461ea998e2","executionInfo":{"status":"ok","timestamp":1546921290176,"user_tz":-480,"elapsed":5899,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!pip install snowballstemmer"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: snowballstemmer in /usr/local/lib/python3.6/dist-packages (1.2.1)\n"],"name":"stdout"}]},{"metadata":{"id":"CmoU6FUODCtR","colab_type":"code","outputId":"6dbc4a67-8898-4537-dd4e-60b135e3ac02","executionInfo":{"status":"ok","timestamp":1546921324221,"user_tz":-480,"elapsed":7348,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":339}},"cell_type":"code","source":["!pip install gensim"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.72)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.72 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.72)\n","Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.72->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.72->boto3->smart-open>=1.2.1->gensim) (0.14)\n"],"name":"stdout"}]},{"metadata":{"id":"0ZZ14CawCS2H","colab_type":"code","colab":{}},"cell_type":"code","source":["#Hownet  （词性）\n","def Tag_wordslist(filepath):\n","    Tag_words = [line.strip() for line in open(filepath,'r',encoding = 'utf-8').readlines()]\n","    return Tag_words\n","CAdverbswords = Tag_wordslist('drive/python3/COAE/Chinese_tag/Adverbs(C).txt')#加载程度副词的路径\n","CNegativeRewords = Tag_wordslist('drive/python3/COAE/Chinese_tag/NegativeRe(C).txt')#加载负面评价词的路径\n","CNegativeSenwords = Tag_wordslist('drive/python3/COAE/Chinese_tag/NegativeSen(C).txt')#加载负面情感词的路径\n","CPositiveRewords = Tag_wordslist('drive/python3/COAE/Chinese_tag/PositiveRe(C).txt')#加载正面评价词的路径\n","CPositiveSenwords = Tag_wordslist('drive/python3/COAE/Chinese_tag/PositiveSen(C).txt')#加载正面情感词的路径\n","CInverwords = Tag_wordslist('drive/python3/COAE/Chinese_tag/Inver(C).txt')#加载否定情感词的路径\n","#stopwords = Tag_wordslist('drive/python3/COAE/Chinese_tag/stopwords_sum.txt')#加载停用词的路径\n","\n","\n","#COAE   读取数据路径，标注分类类别\n","def readCOAE_Pos():\n","    data = []\n","    files= open(\"drive/python3/COAE/COAE6千不分/pos_1.txt\", \"r\",encoding = 'utf-8')  #drive/python3/COAE/train/pos.txt\n","    lines = files.readlines()\n","    for line in lines:\n","        data.append([line,1])\n","    return data\n","def readCOAE_Neg():\n","    data = []\n","    files= open(\"drive/python3/COAE/COAE6千不分/neg_-1.txt\", \"r\",encoding = 'utf-8')\n","    lines = files.readlines()\n","    for line in lines:\n","        data.append([line,0])   \n","    return data\n","\n","Pos = readCOAE_Pos()\n","Neg = readCOAE_Neg()\n","random.shuffle(Pos) #随机打乱数据\n","random.shuffle(Neg) #随机打乱数据\n","train_data = []\n","test_data = []\n","train_data = Pos[664:]+Neg[655:]\n","test_data = Pos[:664]+Neg[:655]\n","random.shuffle(train_data)\n","random.shuffle(test_data)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eowLS10cAyXt","colab_type":"code","outputId":"05840b9c-16c8-4b68-dfde-203452f6c81c","executionInfo":{"status":"ok","timestamp":1556805836916,"user_tz":-480,"elapsed":278931,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["\n","#合工大LTP分词、词性、句法分析\n","def LTP(data):\n","    LTP_DATA_DIR = 'drive/python3/COAE/ltp_data_v3.4.0'       #ltp模型目录的路径\n","    cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n","    segmentor = Segmentor()  # 初始化实例\n","    segmentor.load(cws_model_path)  # 加载模型\n","    #加载词性相关文件\n","    pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')  # 词性标注模型路径，模型名称为`pos.model`\n","    postagger = Postagger() # 初始化实例\n","    postagger.load(pos_model_path)  # 加载模型\n","    #加载句法分析相关文件\n","    par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')  # 依存句法分析模型路径，模型名称为`parser.model`\n","    parser = Parser() # 初始化实例\n","    parser.load(par_model_path)  # 加载模型\n","    datas = []#记录单词\n","    pos_tag = []#记录所有词性\n","    parserss = []#记录句法分析\n","    for review, score in data:\n","        #pyltp分词\n","        words = segmentor.segment(review)  # 分词\n","        words= \" \".join(words).split()\n","        data = []\n","        for word in words:\n","            #if word not in stopwords:#去停用词\n","            data.append(word)    \n","        #pylt词性标注 \n","        postags = postagger.postag(data)  # 词性标注\n","        postags= ' '.join(postags).split()\n","        pos_tag.append(postags)\n","                #依存句法分析\n","        arcs = parser.parse(data, postags)  # 句法分析\n","        parsers = []\n","        for arc in arcs:\n","            parsers.append(arc.relation)   \n","            \n","        datas.append(data) \n","        parserss.append(parsers)\n","    segmentor.release()  # 释放模型 \n","    postagger.release() \n","    parser.release()  \n","    return datas,pos_tag,parserss\n","\n","train_datas = []#记录单词\n","train_tag = []#记录所有词性\n","train_parserss = []#记录句法分析\n","\n","train_datas,train_tag,train_parserss = LTP(train_data)\n","\n","#词\n","tr_te_word = train_datas\n","vocab_word = set(chain(*tr_te_word)) #对所有词进行去重\n","vocab_word_size = len(vocab_word) #统计所以词的个数(不计重复)\n","word_to_idx = {word: i+1 for i, word in enumerate(vocab_word)}  #对去重后的所有词进行重新整理，标注序号，word：id\n","word_to_idx['<unk>'] = 0  \n","idx_to_word = {i+1: word for i, word in enumerate(vocab_word)}  #id：word\n","idx_to_word[0] = '<unk>'\n","\n","#句法依存\n","tr_te_par = train_parserss\n","vocab_par = set(chain(*tr_te_par))\n","vocab_par_size = len(vocab_par)\n","par_to_idx = {word: i+1 for i, word in enumerate(vocab_par)}\n","par_to_idx['<unk>'] = 0\n","idx_to_par= {i+1: word for i, word in enumerate(vocab_par)}\n","idx_to_par[0] = '<unk>'\n","\n","#加载词向量，300维\n","wvmodel = gensim.models.KeyedVectors.load_word2vec_format('drive/python3/COAE/sgns.target.word-character.char1-2.dynwin5.thr10.neg5.dim300.iter5',binary=False)  #300b中文 \n","print(\"end\")\n","wordsList = np.load('drive/python3/COAE/wordsList_Chinese.npy') #加载已经整理好的词List 索引\n","wordsList = wordsList.tolist() \n","embed_size_word = 300  #词向量维度\n","embed_size_tag = 30   #词性向量维度\n","weight_word = torch.zeros(vocab_word_size+3, embed_size_word)   #根据COAE数据集中每个词的id，重新生成的词向量数组 \n","weight_tag = torch.zeros(vocab_word_size+3, embed_size_tag)     #词性向量数组，同上\n","\n","embed_word = nn.Embedding(vocab_word_size+2,embed_size_word) #对于未登录词，进行均匀分布（-0.1，0.1）之间随机初始化\n","embed_word.weight.data.uniform_(-0.1, 0.1)\n","\n","embedd_tag = nn.Embedding(vocab_word_size+3,embed_size_tag) #随机生成一个词性向量，生成范围在（-0.1,0.1）之间\n","embedd_tag.weight.data.uniform_(-1.0, 1.0)\n","\n","for i in range(len(word_to_idx)):\n","    indstr = idx_to_word[i]\n","    indid = word_to_idx[idx_to_word[i]]\n","    if indstr in wordsList:\n","        weight_word[indid, :] = torch.from_numpy(wvmodel.get_vector(indstr))\n","    else:\n","        weight_word[indid, :] = embed_word.weight[indid]#未登录词        \n","    if indstr in CAdverbswords or indstr in CNegativeRewords or indstr in CNegativeSenwords or indstr in CPositiveRewords or indstr in CPositiveSenwords or indstr in CInverwords:\n","        weight_tag[indid, :] = 1.2*embedd_tag.weight[indid]#根据HowNet，来重点标注词（重点词乘以1.2）\n","    else:\n","        weight_tag[indid, :] = embedd_tag.weight[indid]\n","weight_word[vocab_word_size+1, :] = embed_word.weight[vocab_word_size+1]#未登录词  \n","weight_tag[vocab_word_size+1, :] = 1.2*embedd_tag.weight[vocab_word_size+1]\n","weight_tag[vocab_word_size+2, :] = embedd_tag.weight[vocab_word_size+2]"],"execution_count":7,"outputs":[{"output_type":"stream","text":["end\n"],"name":"stdout"}]},{"metadata":{"id":"30QBLI3jCS7n","colab_type":"code","colab":{}},"cell_type":"code","source":["pos_size = vocab_word_size+3\n","pos_dim = 25\n","tag_size = vocab_word_size+3\n","tag_dim = 30\n","parser_size = vocab_word_size+3\n","parser_dim = 25\n","batch_size = 16 \n","#将COAE数据集中每一条样例，进行词语与ID 转化\n","def encode_samples(train_datas,train_tag,train_parserss,maxlen=161):#词特征、位置特征、词性、句法\n","    features = []#词向量\n","    Lists = []#位置\n","    Li_tags = []#词性\n","    Li_pars = []#句法\n","    for sample in train_datas:#词向量、位置、词性\n","        feature = [] \n","        List = []\n","        Li_tag = []#词性\n","        c = 161\n","        for token in sample:#token为一条评论文本里的一个单词\n","            if token in word_to_idx:\n","                feature.append(word_to_idx[token])#词\n","                Li_tag.append(word_to_idx[token])#词性\n","                p = sample.index(token)-len(sample)+maxlen+1  #位置特征向量\n","                List.append(p)\n","            else:\n","                feature.append(vocab_word_size+1) \n","                if token in CAdverbswords or token in CNegativeRewords or token in CNegativeSenwords or token in CPositiveRewords or token in CPositiveSenwords or token in CInverwords:\n","                    Li_tag.append(vocab_word_size+1)\n","                else:\n","                    Li_tag.append(vocab_word_size+2)\n","             \n","                List.append(0)\n","                \n","        features.append(feature)\n","        Lists.append(List)\n","        Li_tags.append(Li_tag)\n","\n","    for sample in train_parserss:#句法\n","       Li_par = []\n","       for token in sample:#token为一条评论文本里的一个单词\n","            if token in par_to_idx:\n","                Li_par.append(par_to_idx[token])\n","            else:\n","                Li_par.append(0)\n","       Li_pars.append(Li_par) \n","    return features,Lists,Li_tags,Li_pars   \n","\n","def pad_samples(features, maxlen=50, PAD=0):#词，每一条样例中，词语个数只保留前50个词，长度大于50直接去掉，小于50，以0填充\n","    padded_features = []\n","    for feature in features:\n","        if len(feature) >= maxlen:\n","            padded_feature = feature[:maxlen]\n","            \n","        else:\n","            padded_feature = feature\n","            while(len(padded_feature) < maxlen):\n","                padded_feature.append(PAD)\n","        padded_features.append(padded_feature)\n","    return padded_features\n","  \n","def pad_list(Lists, maxlen=50, PAD=0):#位置，与词一样\n","    padded_Lists = []  #位置ID\n","    for List in Lists:\n","        if len(List) >= maxlen:\n","            padded_List = List[:maxlen]\n","        else:\n","            padded_List = List\n","            while(len(padded_List) < maxlen):\n","                padded_List.append(PAD)\n","        padded_Lists.append(padded_List)\n","    return padded_Lists\n","\n","def pad_tag(tags, maxlen=50, PAD=0):#词性，一样\n","    padded_Tag = []  #词性ID\n","    for tag in tags:\n","        if len(tag) >= maxlen:\n","            padded_t = tag[:maxlen]\n","        else:\n","            padded_t = tag\n","            while(len(padded_t) < maxlen):\n","                padded_t.append(PAD)\n","        padded_Tag.append(padded_t)\n","    return padded_Tag\n"," \n","def pad_par(parsers, maxlen=50, PAD=0):#句法，一样\n","    padded_Par = []  #词性ID\n","    for tag in parsers:\n","        if len(tag) >= maxlen:\n","            padded_p = tag[:maxlen]\n","        else:\n","            padded_p = tag\n","            while(len(padded_p) < maxlen):\n","                padded_p.append(PAD)\n","        padded_Par.append(padded_p)\n","    return padded_Par\n","\n","#词向量、位置、词性、句法\n","train_fea,train_lis,train_tag,train_pars = encode_samples(train_datas,train_tag,train_parserss)#再传入词性\n","train_features = torch.LongTensor(pad_samples(train_fea))#词特征ID\n","train_Lists = torch.LongTensor(pad_list(train_lis))#位置特征ID\n","train_Tag = torch.LongTensor(pad_tag(train_tag))  #词性特征ID\n","train_parser = torch.LongTensor(pad_par(train_pars))  #句法\n","train_labels= torch.LongTensor([score for _, score in train_data])#标签\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u4RCKyzXGO2m","colab_type":"code","colab":{}},"cell_type":"code","source":["#层归一化\n","class LayerNorm(nn.Module):\n","    def __init__(self, hidden_size, eps=1e-6):\n","        super().__init__()\n","        self.eps = eps\n","       # self.hidden_size = hidden_size*3\n","        self.hidden_size = hidden_size\n","        self.weight = nn.Parameter(torch.ones(self.hidden_size))\n","        self.bias = nn.Parameter(torch.zeros(self.hidden_size))\n","\n","    def forward(self, input):\n","        mu = torch.mean(input, dim=-1, keepdim=True)\n","        sigma = torch.std(input, dim=-1, keepdim=True).clamp(min=self.eps)\n","        output = (input - mu) / sigma\n","        return output * self.weight.expand_as(output) + self.bias.expand_as(output)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w34B7uOF-51B","colab_type":"code","colab":{}},"cell_type":"code","source":["#Bi-LSTM \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Model(nn.Module):\n","    def __init__(self,labels,embedding_dim,embedding_dim_tag,weight,tag,hidden_dim,pos_size,pos_dim,batch,num_layers,tag_size,tag_dim,parser_size,parser_dim):  \n","        super(Model,self).__init__()\n","        self.batch_size = batch #batch_size批次大小\n","        self.embedding_dim_1 = embedding_dim  #词向量维度 300b\n","     \n","        self.hidden_dim = hidden_dim  #隐藏神经单元个数 (128)\n","      \n","        self.labels = labels          #标签大小 2\n","        self.num_layers = num_layers  #隐藏层个数\n","        self.pos_size = pos_size      #位置特征行 pos_size = vocab_size\n","        self.pos_dim = pos_dim        #位置特征维度 25 \n","        self.tag_size = tag_size      #词性特征行 tag_size = vocab_size\n","        self.tag_dim = tag_dim        #词性特征维度 30 \n","        self.parser_size = parser_size  #句法特征行 parser_size = vocab_size\n","        self.parser_dim  = parser_dim   #句法特征维度 25\n","        self.bidirectional = True    #False为LSTM True为Bilstm\n","        self.num_directions = 2 if self.bidirectional else 1 \n","        self.embedding_1 = nn.Embedding.from_pretrained(weight) #引入词向量\n","        self.embedding_1.weight.requires_grad = False\n","        \n","        self.tag_embeds = nn.Embedding.from_pretrained(tag) #引入词性向量30(对情感词，否定词，副词*1.2权值)\n","        self.tag_embeds.weight.requires_grad = False\n"," \n","        self.pos_embeds = nn.Embedding(self.pos_size,self.pos_dim) #位置特征25（随机） \n","        \n","        self.parser_embeds = nn.Embedding(self.parser_size,self.parser_dim)  #依存分析树25（随机）\n","      \n","        self.lstm_1 = nn.LSTM(input_size=self.embedding_dim_1+self.pos_dim,\n","                              hidden_size=self.hidden_dim,\n","                              num_layers=self.num_layers, \n","                              bidirectional=self.bidirectional,\n","                              dropout=0,\n","                              batch_first = True\n","                             )#125b（词+位置）\n","        \n","        self.lstm_2 = nn.LSTM(input_size=self.embedding_dim_1+self.tag_dim,\n","                              hidden_size=self.hidden_dim,\n","                              num_layers=self.num_layers, \n","                              bidirectional=self.bidirectional,\n","                              dropout=0,\n","                              batch_first = True\n","                             )#130b（词+词性）\n","        \n","        self.lstm_3 = nn.LSTM(input_size=self.embedding_dim_1+self.parser_dim,\n","                              hidden_size=self.hidden_dim,\n","                              num_layers=self.num_layers, \n","                              bidirectional=self.bidirectional,\n","                              dropout=0,\n","                              batch_first = True\n","                             )#125b(词+依存分析)\n","        self.ln = LayerNorm(self.hidden_dim * self.num_directions) \n","        self.Linear = nn.Linear(self.hidden_dim * self.num_directions*3,self.hidden_dim) #线性层768-》128\n","        self.logistic_1 = nn.Linear(self.hidden_dim,self.labels)#128-》2\n","        self.dropout=nn.Dropout(p=0.5)\n","        self.dropout_emb=nn.Dropout(p=0.3)\n","        self._init_weights()\n","    \n","    #初始化：pos_embeds、parser_embeds      \n","    def _init_weights(self, scope=1.):\n","        self.pos_embeds.weight.data.uniform_(-scope,scope)\n","        self.parser_embeds.weight.data.uniform_(-scope,scope)\n"," \n","    def forward(self,sentence,pos,tag,parse):\n","        embeds_1 = torch.cat(((self.embedding_1(sentence)),(self.pos_embeds(pos))),2) #词向量+位置 拼接 325\n","        embeds_2 = torch.cat(((self.embedding_1(sentence)) , (self.tag_embeds(tag))),2)  #词向量+词性 拼接 330\n","        embeds_3 = torch.cat(((self.embedding_1(sentence)) , (self.parser_embeds(parse))),2) #词向量+句法 拼接 325\n"," \n","        states_1, hidden = self.lstm_1(embeds_1)#Bi-LSTM\n","        states_2, hidden = self.lstm_2(embeds_2)#Bi-LSTM\n","        states_3, hidden = self.lstm_3(embeds_3)#Bi-LSTM\n","        \n","        #转置\n","        states_1 = torch.transpose(states_1,0,1)\n","        states_2 = torch.transpose(states_2,0,1)\n","        states_3 = torch.transpose(states_3,0,1)\n","        \n","        #tanh激励函数\n","        states_1 = F.tanh(states_1)\n","        states_2 = F.tanh(states_2)\n","        states_3 = F.tanh(states_3)\n"," \n","        #层归一化\n","        states_1 = self.ln(states_1)[-1]\n","        states_2 = self.ln(states_2)[-1]\n","        states_3 = self.ln(states_3)[-1]\n","       \n","        #tanh激励函数\n","        states_1 = F.tanh(states_1)\n","        states_2 = F.tanh(states_2)\n","        states_3 = F.tanh(states_3)\n","        \n","        output = torch.cat([states_1,states_2,states_3],1) #将三个通道结果，进行拼接，融合\n","        output = self.Linear(output)#线性层 768-》128\n","        output = F.relu(output)#relu激励\n","        return F.log_softmax(self.logistic_1(output))#128->2\n","        \n","       "],"execution_count":0,"outputs":[]},{"metadata":{"id":"-vtkaZu2CTJ8","colab_type":"code","outputId":"42450d73-5f2b-48b6-d584-33840f375c64","executionInfo":{"status":"ok","timestamp":1556806213526,"user_tz":-480,"elapsed":1364,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"cell_type":"code","source":["#1\n","device = torch.device('cuda:0')\n","# 定义device，是否使用GPU，依据计算机配置自动会选择\n","#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#model= Model_1(labels,vocab_size+1,embed_size,embed_size_tag,weight,weight_tag,num_hiddens,pos_size,pos_dim,batch_size,num_layers)\n","model= Model(labels,embed_size,embed_size_tag,weight_word,weight_tag,num_hiddens,pos_size,pos_dim,batch_size,num_layers,tag_size,tag_dim,parser_size,parser_dim)\n","print(model)\n","model.to(device)\n","#model = model.cuda()\n","loss_function = nn.CrossEntropyLoss()# size_average默认情况下是True，对每个小批次的损失取平均值。 但是，如果字段size_average设置为False\n","#optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.3,weight_decay=3e-8)\n","#optimizer = optim.SGD(model.parameters(), lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","#optimizer = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01, rho=0.9, eps=1e-06, weight_decay=0.001)#filter(lambda p: p.requires_grad, model.parameters())\n","\n","#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n","optimizer = optim.Adagrad(model.parameters(), lr=0.01,  weight_decay=0.001)\n","#optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.9, eps=1e-06, weight_decay=0.001)#Adam\n","#optimizer = optim.Adagrad([\n","#                       {'params': model.embedding_1.parameters(),'lr':0.009}\n","#                      ], lr=0.09,weight_decay=5e-4)\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Model(\n","  (embedding_1): Embedding(17620, 300)\n","  (tag_embeds): Embedding(17620, 30)\n","  (pos_embeds): Embedding(17620, 25)\n","  (parser_embeds): Embedding(17620, 25)\n","  (lstm_1): LSTM(325, 128, num_layers=2, batch_first=True, bidirectional=True)\n","  (lstm_2): LSTM(330, 128, num_layers=2, batch_first=True, bidirectional=True)\n","  (lstm_3): LSTM(325, 128, num_layers=2, batch_first=True, bidirectional=True)\n","  (ln): LayerNorm()\n","  (Linear): Linear(in_features=768, out_features=128, bias=True)\n","  (logistic_1): Linear(in_features=128, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.5)\n","  (dropout_emb): Dropout(p=0.3)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"CYrYmnWKCTHh","colab_type":"code","colab":{}},"cell_type":"code","source":["#1\n","train_set = torch.utils.data.TensorDataset(train_features,train_Lists,train_Tag,train_parser,train_labels)\n","#test_set = torch.utils.data.TensorDataset(test_features,test_Lists,test_Tag,test_parser,test_labels)\n","\n","train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True)\n","#test_iter = torch.utils.data.DataLoader(test_set, batch_size=batch_size,shuffle=False)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7tJGWUp-UgLa","colab_type":"code","colab":{}},"cell_type":"code","source":["test_datas = []#记录单词\n","test_tag = []#记录所有词性\n","test_parserss = []#记录句法分析\n","test_datas,test_tag,test_parserss = LTP(test_data)\n","\n","test_fea,test_lis,test_tag,test_pars = encode_samples(test_datas,test_tag,test_parserss)\n","test_features = torch.LongTensor(pad_samples(test_fea))\n","test_Lists = torch.LongTensor(pad_list(test_lis))\n","test_Tag = torch.LongTensor(pad_tag(test_tag))  #词性特征ID\n","test_parser = torch.LongTensor(pad_par(test_pars))  #句法\n","test_labels= torch.LongTensor([score for _, score in test_data])\n","\n","test_set = torch.utils.data.TensorDataset(test_features,test_Lists,test_Tag,test_parser,test_labels)\n","test_iter = torch.utils.data.DataLoader(test_set, batch_size=batch_size,shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vwIBYEdsk1FW","colab_type":"code","outputId":"5d992e35-e27b-419e-852d-42c63b64d117","executionInfo":{"status":"error","timestamp":1556806524429,"user_tz":-480,"elapsed":264034,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":1702}},"cell_type":"code","source":["num_epochs = 140#94\n","for epoch in range(num_epochs):\n","    print(\"epoch:%d\" %epoch)\n","    acc=0 \n","    total=0\n","    running_loss=0.0\n","    test_losses=0.0\n","    n = 0.0\n","    m= 0.0\n","    model.train()\n","    for train_i in train_iter:\n","        n += 1\n","        x_train_wvm = Variable(train_i[0].cuda())\n","        x_train_pos = Variable(train_i[1].cuda())\n","        x_train_tag = Variable(train_i[2].cuda())\n","        x_train_parser = Variable(train_i[3].cuda())\n","        label = Variable(train_i[4].cuda())\n","        y = model(x_train_wvm,x_train_pos,x_train_tag,x_train_parser) #词向量+位置特征向量\n","        loss = loss_function(y, label)\n","        optimizer.zero_grad() #将参数的grad值初始化为0\n","        loss.backward()#\n","        optimizer.step()    \n","         \n","        y = np.argmax(y.cpu().data.numpy(),axis=1)\n","        running_loss += float(loss)\n","        for y1,y2 in zip(y,label):\n","            if y1==y2:\n","                acc+=1\n","            total+=1\n","    #print(n)\n","    #print(len(train_iter.dataset))\n","    print(\"loss:%.5f,train:%.4f %%\" %(float(running_loss)/n,(100*float(acc)/total)))\n"," \n","   #acc_t = 0\n","   # total_t = 0\n","    count_predict = [0,0]\n","    count_total = [0,0]\n","    count_right = [0,0]\n","    test_acc = 0.0\n","    #with torch.no_grad():  # no grad when test and predict\n","    model.eval()\n","    #hidden = model.init_hidden()\n","    m = 0\n","    for test_i in test_iter:\n","        m += 1\n","       \n","        x_test_wvm = Variable(test_i[0].cuda())\n","        x_test_pos = Variable(test_i[1].cuda())\n","        x_test_tag = Variable(test_i[2].cuda())\n","        x_test_parser = Variable(test_i[3].cuda())\n","        test_label = Variable(test_i[4].cuda())\n","        \n","        yy = model(x_test_wvm,x_test_pos,x_test_tag,x_test_parser)\n","        \n","        test_loss = loss_function(yy, test_label)\n","        test_losses += test_loss\n","        y = np.argmax(yy.cpu().data.numpy(),axis=1)\n","        \n","        test_acc += accuracy_score(torch.argmax(yy.cpu().data,\n","                                                    dim=1), test_label.cpu())\n","        for y1,y2 in zip(y,test_label):\n","            count_predict[y1]+=1\n","            count_total[y2]+=1\n","            if y1==y2:\n","                count_right[y1]+=1\n","\n","    #print(count_predict)\n","    #print(count_total)\n","   # print(count_right)\n","    precision = [0,0]\n","    recall = [0,0]\n","    for i in range(len(count_predict)):\n","        if count_predict[i]!=0:\n","            precision[i] = float(count_right[i])/count_predict[i]\n","            recall[i] = float(count_right[i])/count_total[i]\n","    \n","    precision = sum(precision)/len(precision)\n","    recall = sum(recall)/len(recall)    \n","\n","    print(\"loss:%.5f , 准确率：%.3f , 召回率：%.3f , f：%.3f   | %.3f\" %(test_losses.data/m,precision,recall,(2*precision*recall)/(precision+recall),test_acc/m))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["epoch:0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["loss:0.68023,train:56.5691 %\n","loss:0.64594 , 准确率：0.673 , 召回率：0.601 , f：0.635   | 0.603\n","epoch:1\n","loss:0.61525,train:62.8925 %\n","loss:0.46449 , 准确率：0.811 , 召回率：0.808 , f：0.810   | 0.809\n","epoch:2\n","loss:0.54121,train:73.3604 %\n","loss:0.41645 , 准确率：0.853 , 召回率：0.838 , f：0.846   | 0.836\n","epoch:3\n","loss:0.55582,train:69.8141 %\n","loss:0.48463 , 准确率：0.814 , 召回率：0.771 , f：0.792   | 0.768\n","epoch:4\n","loss:0.50481,train:73.8945 %\n","loss:0.51440 , 准确率：0.797 , 召回率：0.711 , f：0.752   | 0.711\n","epoch:5\n","loss:0.46195,train:77.3553 %\n","loss:0.52721 , 准确率：0.746 , 召回率：0.641 , f：0.689   | 0.643\n","epoch:6\n","loss:0.45363,train:78.1243 %\n","loss:0.42419 , 准确率：0.837 , 召回率：0.830 , f：0.833   | 0.830\n","epoch:7\n","loss:0.56235,train:68.8314 %\n","loss:0.66036 , 准确率：0.745 , 召回率：0.547 , f：0.631   | 0.543\n","epoch:8\n","loss:0.45985,train:78.5302 %\n","loss:0.41297 , 准确率：0.849 , 召回率：0.847 , f：0.848   | 0.847\n","epoch:9\n","loss:0.43989,train:81.0938 %\n","loss:0.50158 , 准确率：0.804 , 召回率：0.735 , f：0.768   | 0.733\n","epoch:10\n","loss:0.47866,train:76.1376 %\n","loss:0.44502 , 准确率：0.831 , 召回率：0.831 , f：0.831   | 0.831\n","epoch:11\n","loss:0.55009,train:67.7206 %\n","loss:0.53533 , 准确率：0.776 , 召回率：0.697 , f：0.735   | 0.694\n","epoch:12\n","loss:0.50693,train:72.3563 %\n","loss:0.50093 , 准确率：0.778 , 召回率：0.752 , f：0.764   | 0.749\n","epoch:13\n","loss:0.49915,train:76.1162 %\n","loss:0.53880 , 准确率：0.790 , 召回率：0.769 , f：0.780   | 0.769\n","epoch:14\n","loss:0.55094,train:70.1346 %\n","loss:0.44482 , 准确率：0.832 , 召回率：0.817 , f：0.825   | 0.817\n","epoch:15\n","loss:0.51687,train:73.1254 %\n","loss:0.56610 , 准确率：0.736 , 召回率：0.708 , f：0.722   | 0.712\n","epoch:16\n","loss:0.55057,train:69.0023 %\n","loss:0.53446 , 准确率：0.793 , 召回率：0.679 , f：0.732   | 0.677\n","epoch:17\n","loss:0.44608,train:78.5302 %\n","loss:0.48217 , 准确率：0.822 , 召回率：0.763 , f：0.791   | 0.762\n","epoch:18\n","loss:0.42397,train:80.6238 %\n","loss:0.36901 , 准确率：0.871 , 召回率：0.863 , f：0.867   | 0.862\n","epoch:19\n","loss:0.31342,train:87.8231 %\n","loss:0.32544 , 准确率：0.877 , 召回率：0.871 , f：0.874   | 0.873\n","epoch:20\n","loss:0.29639,train:88.7631 %\n","loss:0.28630 , 准确率：0.883 , 召回率：0.882 , f：0.882   | 0.883\n","epoch:21\n","loss:0.27404,train:90.0021 %\n","loss:0.31544 , 准确率：0.887 , 召回率：0.881 , f：0.884   | 0.882\n","epoch:22\n","loss:0.25919,train:90.1303 %\n","loss:0.29512 , 准确率：0.888 , 召回率：0.877 , f：0.882   | 0.877\n","epoch:23\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-412650f62191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#将参数的grad值初始化为0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"LMHlwzR2CTFL","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","Loss_list = []\n","Accuracy_list =[]#25\n","num_epochs = 200#94\n","for epoch in range(num_epochs):\n","    print(\"epoch:%d\" %epoch)\n","    acc=0 \n","    total=0\n","    running_loss=0.0\n","    test_losses=0.0\n","    n = 0.0\n","    m= 0.0\n","    model.train()\n","   # Hidden = model.init_hidden()\n","    for train_i in train_iter:\n","        n += 1\n","       #cuda()\n","       # model.zero_grad()\n","        x_train_wvm = Variable(train_i[0].cuda())\n","        x_train_pos = Variable(train_i[1].cuda())\n","        x_train_tag = Variable(train_i[2].cuda())\n","        x_train_parser = Variable(train_i[3].cuda())\n","        label = Variable(train_i[4].cuda())\n","        y = model(x_train_wvm,x_train_pos,x_train_tag,x_train_parser) #词向量+位置特征向量\n","       \n","      #  l2_reg = 0\n","       # for param in model.parameters():\n","      #      l2_reg += torch.norm(param)\n","       # w,b =[param.item() for param in model.parameters()]\n","        \n","        loss = loss_function(y, label)\n","       # loss += reg_lambad * l2_reg\n","        optimizer.zero_grad() #将参数的grad值初始化为0\n","        loss.backward()#\n","        optimizer.step()    \n","         \n","        y = np.argmax(y.cpu().data.numpy(),axis=1)\n","        running_loss += float(loss)\n","        for y1,y2 in zip(y,label):\n","            if y1==y2:\n","                acc+=1\n","            total+=1\n","    #print(n)\n","    #print(len(train_iter.dataset))\n","    print(\"loss:%.5f,train:%.4f %%\" %(float(running_loss)/n,(100*float(acc)/total)))\n","    Loss_list.append(float(running_loss)/total)\n","    Accuracy_list.append((100*float(acc)/total))\n","torch.save(model, \"drive/python3/COAE/model_COAE_LSTM_1.pkl\")\n","print (\"model has been saved\")\n","#model_COAE_BiLSTM 72.65"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U3ua8jF9UWpe","colab_type":"code","outputId":"d5534a30-393e-4781-c6f4-0d0cb0591815","executionInfo":{"status":"ok","timestamp":1552549610375,"user_tz":-480,"elapsed":2708,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"cell_type":"code","source":["#test\n","count_predict = [0,0]\n","count_total = [0,0]\n","count_right = [0,0]\n","test_acc = 0.0\n","m = 0\n","net = torch.load(\"drive/python3/COAE/model_COAE_LSTM_1.pkl\")\n","\n","net.eval()\n","model.eval()\n","for test_i in test_iter:\n","    m += 1\n","    x_test_wvm = Variable(test_i[0].cuda())\n","    x_test_pos = Variable(test_i[1].cuda())\n","    x_test_tag = Variable(test_i[2].cuda())\n","    x_test_parser = Variable(test_i[3].cuda())\n","    test_label = Variable(test_i[4].cuda())\n","    yy = model(x_test_wvm,x_test_pos,x_test_tag,x_test_parser)\n","    test_loss = loss_function(yy, test_label)\n","    test_losses += test_loss\n","    y = np.argmax(yy.cpu().data.numpy(),axis=1)\n","    test_acc += accuracy_score(torch.argmax(yy.cpu().data, dim=1), test_label.cpu())\n","    for y1,y2 in zip(y,test_label):\n","        count_predict[y1]+=1\n","        count_total[y2]+=1\n","   #     print(\"%d,%d\" %(y1,y2))\n","        if y1==y2:\n","            count_right[y1]+=1\n","\n","precision = [0,0]\n","recall = [0,0]\n","for i in range(len(count_predict)):\n","    if count_predict[i]!=0:\n","        precision[i] = float(count_right[i])/count_predict[i]\n","        recall[i] = float(count_right[i])/count_total[i]\n","    \n","precision = sum(precision)/len(precision)\n","recall = sum(recall)/len(recall)    \n","print(\"loss:%.5f , 准确率：%.3f , 召回率：%.3f , f：%.3f   |准确率 %.3f\" %(test_losses.data/m,precision,recall,(2*precision*recall)/(precision+recall),test_acc/m))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["loss:0.53892 , 准确率：0.905 , 召回率：0.904 , f：0.905   |准确率 0.906\n"],"name":"stdout"}]},{"metadata":{"id":"jfBKt_IuZuWS","colab_type":"code","colab":{}},"cell_type":"code","source":["#中文8个样例处理\n","import codecs\n","def COAE_test_end():\n","    data = []\n","   # with codecs.open('drive/python3/COAE/pn.txt','r','utf-8') as f:#'drive/python3/COAE/COAE_col.txt\n","    with codecs.open('drive/python3/COAE/COAE_col.txt','r','utf-8') as f:\n","        for line in f:\n","            lines = line[2:]\n","            if line[0] =='1':\n","                data.append([lines,1])\n","            else:\n","                data.append([lines,0])\n","    return data\n","test_data_end = COAE_test_end()\n","\n","test_datas_end = []#记录单词\n","test_tag_end = []#记录所有词性\n","test_parserss_end = []#记录句法分析\n","test_datas_end,test_tag_end,test_parserss_end = LTP(test_data_end)\n","\n","test_fea_end,test_lis_end,test_tag_end,test_pars_end = encode_samples(test_datas_end,test_tag_end,test_parserss_end)\n","\n","test_features_end = torch.LongTensor(pad_samples(test_fea_end))\n","test_Lists_end = torch.LongTensor(pad_list(test_lis_end))\n","test_Tag_end = torch.LongTensor(pad_tag(test_tag_end))  #词性特征ID\n","test_parser_end = torch.LongTensor(pad_par(test_pars_end))  #句法\n","test_labels_end= torch.LongTensor([score for _, score in test_data_end])\n","\n","test_set_end = torch.utils.data.TensorDataset(test_features_end,test_Lists_end,test_Tag_end,test_parser_end,test_labels_end)\n","test_iter_end = torch.utils.data.DataLoader(test_set_end, batch_size=batch_size,shuffle=False)#False\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y1ZOiLQTZuna","colab_type":"code","outputId":"e08442d3-5235-4348-cc3a-933ede610e88","executionInfo":{"status":"ok","timestamp":1552550999157,"user_tz":-480,"elapsed":31866,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":373}},"cell_type":"code","source":["#中文8个样例对比测试\n","count_predict = [0,0]\n","count_total = [0,0]\n","count_right = [0,0]\n","test_acc = 0.0\n","m = 0\n","net = torch.load(\"drive/python3/COAE/model_COAE_BiLSTM.pkl\")\n","for test_i in test_iter_end:\n","    m += 1\n","    x_test_wvm = Variable(test_i[0].cuda())\n","    x_test_pos = Variable(test_i[1].cuda())\n","    x_test_tag = Variable(test_i[2].cuda())\n","    x_test_parser = Variable(test_i[3].cuda())\n","    test_label = Variable(test_i[4].cuda())\n","    yy = model(x_test_wvm,x_test_pos,x_test_tag,x_test_parser)\n","    test_loss = loss_function(yy, test_label)\n","    test_losses += test_loss\n","    y = np.argmax(yy.cpu().data.numpy(),axis=1)\n","    test_acc += accuracy_score(torch.argmax(yy.cpu().data, dim=1), test_label.cpu())\n","    for y1,y2 in zip(y,test_label):\n","        count_predict[y1]+=1\n","        count_total[y2]+=1\n","        print(\"%d,%d\" %(y1,y2))\n","        if y1==y2:\n","            count_right[y1]+=1\n","\n","precision = [0,0]\n","recall = [0,0]\n","for i in range(len(count_predict)):\n","    if count_predict[i]!=0:\n","          precision[i] = float(count_right[i])/count_predict[i]\n","          recall[i] = float(count_right[i])/count_total[i]\n","    \n","precision = sum(precision)/len(precision)\n","recall = sum(recall)/len(recall)    \n","print(\"loss:%.5f , 准确率：%.4f , 召回率：%.4f , f：%.4f   |准确率 %.4f\" %(test_losses.data/m,precision,recall,(2*precision*recall)/(precision+recall),test_acc/m))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0,0\n","1,1\n","0,1\n","0,0\n","0,0\n","0,1\n","0,0\n","0,0\n","loss:0.65570 , 准确率：0.8571 , 召回率：0.6667 , f：0.7500   |准确率 0.7500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"metadata":{"id":"OLHhyezp_T9Y","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"54gZ0jHmCTMe","colab_type":"code","colab":{}},"cell_type":"code","source":["#BiLSTM\n","\n","class Model3(nn.Module):\n","    def __init__(self,labels,vocab_size,embedding_dim,embedding_dim_tag,weight,tag,hidden_dim,pos_size,pos_dim,batch,num_layers,tag_size,tag_dim):  \n","        super(Model3,self).__init__()\n","        self.batch_size = batch\n","        self.embedding_dim_1 = embedding_dim  #100 model_1\n","        self.embedding_dim_2 = embedding_dim_tag  #130 model_2\n","        self.hidden_dim = hidden_dim  \n","        self.vocab_size = vocab_size  \n","        self.labels = labels\n","        self.num_layers = num_layers\n","        self.pos_size = pos_size  \n","        self.pos_dim = pos_dim  #25\n","        self.tag_size = tag_size  \n","        self.tag_dim = tag_dim  #30\n","        \n","        self.bidirectional = True\n","        self.num_directions = 2 if self.bidirectional else 1#2\n","        \n","        self.embedding_1 = nn.Embedding.from_pretrained(weight)\n","        self.embedding_1.weight.requires_grad = False\n","        self.tag_embeds = nn.Embedding.from_pretrained(tag)#weight_tag为7*30\n","        self.tag_embeds.weight.requires_grad = False\n","        self.pos_embeds = nn.Embedding(self.pos_size,self.pos_dim)#位置特征 pos_dim :25维 \n","        \n","        self.lstm_1 = nn.LSTM(input_size=self.embedding_dim_1,\n","                              hidden_size=self.hidden_dim,\n","                              num_layers=self.num_layers, \n","                              bidirectional=self.bidirectional,\n","                              dropout=0,\n","                              batch_first = True\n","                             )#125b\n","        self.ln = LayerNorm(self.hidden_dim * self.num_directions)\n","        self.logistic = nn.Linear(self.hidden_dim * self.num_directions,self.labels)\n","        \n","        #if self.bidirectional:\n","        #    self.decoder2 = nn.Linear(hidden_size * 2, labels)\n","       # else:\n","         #   self.decoder2 = nn.Linear(hidden_size * , labels)\n","        self.dropout=nn.Dropout(p=0.5)\n","        self.dropout_emb=nn.Dropout(p=0.3)\n","        \n","        self._init_weights()\n","          \n","    def _init_weights(self, scope=1.):\n","        self.logistic.weight.data.uniform_(-scope, scope)\n","        self.logistic.bias.data.fill_(0)\n","\n","    def init_hidden(self):\n","        num_layer = self.num_layers * self.num_directions\n","        weight = next(self.parameters()).data\n","        return (Variable(weight.new(num_layer, self.batch_size, self.hidden_dim).zero_()), Variable(weight.new(num_layer, self.batch_size, self.hidden_dim).zero_()))\n","\n","    def forward(self,sentence,pos,tag,hidden):#加tag\n","        encode = self.embedding_1(sentence)\n","        #encoding_1 = self.dropout_emb(encode)#对拼接后的层dropout\n","        lstm_out, hidden = self.lstm_1(encode, hidden)\n","        \n","        lstm_out = torch.transpose(lstm_out,0,1)\n","        lstm_out = F.tanh(lstm_out)\n","        output = self.ln(lstm_out)[-1]\n","        output = F.tanh(output)\n","        return F.log_softmax(self.logistic(output))\n","      \n","      \n","       # embeds_1 = self.embedding_1(sentence)\n","        #encoding_1 = self.dropout_emb(embeds_1)#对拼接后的层dropout\n","       # states_1, hidden = self.lstm_1(embeds_1.transpose(0, 1),hidden)\n","       # print(states_1.size())\n","      \n","        #states_1 = torch.transpose(states_1,1,2)\n","        #encoding_1 = F.tanh(states_1)\n","     \n","        #states_1 = F.max_pool1d(states_1,states_1.size(2))\n","        #states_1 = states_1.squeeze()#2\n","        #outputs = F.tanh(states_1)\n","       # encoding_1 = F.dropout(encoding_1, p=0.5)#对拼接后的层dropout\n","        #outputs = self.decoder(encoding_1)\n","       # outputs = self.decoder2(encoding_1)\n","       # outputs = F.log_softmax(self.logistic(outputs))\n","        #print(outputs.size())\n","       # return outputs\n","      "],"execution_count":0,"outputs":[]},{"metadata":{"id":"_zY904fAZy8l","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"HHIn86BRCTC0","colab_type":"code","outputId":"fcbb7afd-b46e-4cdb-ea37-16eba5ddf2e1","executionInfo":{"status":"error","timestamp":1556514901128,"user_tz":-480,"elapsed":275301,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":847}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","!apt-get install -f\n","!apt-get -y install -qq fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","--2019-04-29 05:10:56--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","Resolving launchpad.net (launchpad.net)... 91.189.89.223, 91.189.89.222, 2001:67c:1560:8003::8004, ...\n","Connecting to launchpad.net (launchpad.net)|91.189.89.223|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2019-04-29 05:10:57 ERROR 404: Not Found.\n","\n","\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb': No such file or directory\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-410\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7d3a6017178e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"hkz8cNuaDRF3","colab_type":"code","outputId":"1c2c6eba-e0e2-4a84-bda2-3cd86cd1b187","executionInfo":{"status":"ok","timestamp":1556514556791,"user_tz":-480,"elapsed":14028,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"cell_type":"code","source":["!add-apt-repository -y  ppa:alessandro-strada/ppa"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,609 B]\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu bionic InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,639 kB]\n","Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [788 kB]\n","Fetched 2,698 kB in 5s (494 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"metadata":{"id":"SY_1WCMYDRYH","colab_type":"code","outputId":"0a2886df-6e21-45ba-f549-91552573c568","executionInfo":{"status":"ok","timestamp":1556514566585,"user_tz":-480,"elapsed":5543,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"cell_type":"code","source":["!apt-get update"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.161)] [Connecting to security.u\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.161)] [Connecting to security.u\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.161)] [Connecting to security.u\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.161)] [Connecting to security.u\r0% [3 InRelease gpgv 3,609 B] [Connecting to archive.ubuntu.com (91.189.88.161)\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","\r0% [3 InRelease gpgv 3,609 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:6 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu bionic InRelease\n","\r0% [3 InRelease gpgv 3,609 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [3 InRelease gpgv 3,609 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rGet:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Fetched 252 kB in 2s (126 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"metadata":{"id":"XxfbkHK6DRVa","colab_type":"code","outputId":"25b4cdc7-fb88-4c46-be40-bd932c449b78","executionInfo":{"status":"ok","timestamp":1556514571748,"user_tz":-480,"elapsed":4374,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"cell_type":"code","source":["!apt install w3m"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","w3m is already the newest version (0.5.3-36build1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-410\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n"],"name":"stdout"}]},{"metadata":{"id":"opC4agQaDRRY","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get -y install -qq google-drive-ocamlfuse fuse"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_HI6puPBDRNo","colab_type":"code","outputId":"9baad83d-eacb-4028-cb2c-399d4393296e","executionInfo":{"status":"ok","timestamp":1556514582520,"user_tz":-480,"elapsed":8003,"user":{"displayName":"漆芳","photoUrl":"","userId":"07231107937433162378"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!ls drive\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n","'Colab Notebooks'   python3\n"],"name":"stdout"}]}]}